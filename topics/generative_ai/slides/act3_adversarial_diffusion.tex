% Slide 12: Human introspection: Artists improve through critique
\begin{frame}
\frametitle{Human Learning Analogy}
\framesubtitle{How Artists Develop Mastery}

\begin{center}
\includegraphics[width=0.55\textwidth]{charts/artist_learning_process.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Art Education:}
\begin{itemize}
\item Student creates
\item Teacher critiques
\item Student improves
\item Competitive dynamics: Both improve through opposition
\end{itemize}

\column{0.48\textwidth}
\textbf{Insights:}
\begin{itemize}
\item Adversarial feedback drives improvement
\item Both improve together
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Adversarial learning mirrors competitive skill development - discriminator pressure forces generator improvement, creating arms race driving both toward excellence (inspired GANs - Goodfellow et al. 2014)
}
\end{frame}

% Slide 13: Hypothesis: Adversarial training OR iterative denoising
\begin{frame}
\frametitle{Two Revolutionary Approaches}
\framesubtitle{Beyond VAEs to Better Generation}

\begin{center}
\includegraphics[width=0.55\textwidth]{charts/two_approaches.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textcolor{mlred}{\textbf{Adversarial}}
\begin{itemize}
\item Two networks compete
\item Sharp, realistic
\item No explicit likelihood
\end{itemize}

\column{0.48\textwidth}
\textcolor{mlblue}{\textbf{Diffusion}}
\begin{itemize}
\item Iterative denoising
\item Stable, controllable
\item Likelihood-based, traceable gradients
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Adversarial and diffusion approaches overcome VAE's MSE averaging problem through different mechanisms - competition vs iterative refinement both avoid explicit averaging
}
\end{frame}

% Slide 14: Zero-jargon: "Forger vs detective game" (GAN)
\begin{frame}
\frametitle{GANs: The Forger vs Detective Game}
\framesubtitle{Adversarial Training in Plain English}

\begin{center}
\includegraphics[width=0.55\textwidth]{charts/forger_detective_analogy.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textcolor{mlred}{\textbf{Forger:}}
\begin{itemize}
\item Creates fakes
\item Fools detective
\end{itemize}

\column{0.48\textwidth}
\textcolor{mlblue}{\textbf{Detective:}}
\begin{itemize}
\item Examines: real/fake?
\item Gets better at detection
\end{itemize}
\end{columns}

\vspace{0.2cm}
\textcolor{mlgreen}{\textbf{Result:}} Detective can't tell fake from real!

\textbf{Equilibrium:} When forger succeeds 50\% of time

\vspace{\fill}
\footnotesize \textcolor{gray}{
Competition drives both to excellence
}
\end{frame}

% Slide 15: Zero-jargon: "Reverse corruption" (diffusion)
\begin{frame}
\frametitle{Diffusion: The Reverse Corruption Process}
\framesubtitle{Denoising in Plain English}

\begin{center}
\includegraphics[width=0.55\textwidth]{charts/reverse_corruption_analogy.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Forward:}
\begin{itemize}
\item Clean -> noise
\item 1000 steps
\end{itemize}

\column{0.48\textwidth}
\textbf{Reverse:}
\begin{itemize}
\item Noise -> clean
\item 1000 steps
\item Training: Learn to predict noise at each step
\item Inference: Start from pure noise, denoise 1000 times
\end{itemize}
\end{columns}

\vspace{0.2cm}
\textcolor{mlgreen}{\textbf{Key:}} Learn to undo corruption

\vspace{\fill}
\footnotesize \textcolor{gray}{
Diffusion inverts gradual noise corruption process - learning reverse process enables sampling by denoising pure noise, avoiding VAE averaging through iterative refinement
}
\end{frame}

% Slide 16: Geometric intuition: Generator/discriminator dynamics
\begin{frame}
\frametitle{GAN Dynamics: Geometric View}
\framesubtitle{Understanding the Adversarial Process (Goodfellow et al. 2014)}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/gan_geometric_dynamics.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Generator:}
\begin{itemize}
\item Maps $z$ to $x$
\item Loss: $-\log D(G(z))$
\end{itemize}

\textbf{Minimax objective:}
$$\min_G \max_D V(D,G)$$

\column{0.48\textwidth}
\textbf{Discriminator:}
\begin{itemize}
\item Separates real/fake
\item Loss: $-\log D(x) - \log(1-D(G))$
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Nash equilibrium occurs when $p_g = p_{data}$ and discriminator accuracy equals 50\% - adversarial objective mathematically guarantees convergence under ideal conditions
}
\end{frame}

% Slide 17: Full walkthrough: GAN iteration with actual loss values
\begin{frame}
\frametitle{GAN Training: Step-by-Step Example}
\framesubtitle{Real Loss Values from MNIST Training}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/gan_training_walkthrough.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Epoch 1:}
\begin{itemize}
\item D: 1.386, G: 0.693
\item Images: noise
\end{itemize}

\column{0.48\textwidth}
\textbf{Epoch 100:}
\begin{itemize}
\item D: 0.695, G: 0.698
\item Images: realistic
\end{itemize}
\end{columns}

\textbf{Healthy:} Total $\approx$ 1.4

\textbf{Interpretation:}
\begin{itemize}
\item D loss $\approx$ 0.7 = balanced (both fooling each other)
\item Unhealthy: D$\to$0 (G wins), D$\to$1.4 (D wins) = failure
\end{itemize}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Training dynamics reveal health - balanced losses near 0.69 indicate Nash equilibrium, divergence signals mode collapse or vanishing gradients requiring intervention
}
\end{frame}

% Slide 18: Diffusion forward/reverse process
\begin{frame}
\frametitle{Diffusion Mathematical Framework}
\framesubtitle{Forward and Reverse Processes (Ho et al. 2020 - DDPM)}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/diffusion_mathematics.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Forward:}
$$q(x_t|x_{t-1}) = \mathcal{N}(\sqrt{1-\beta_t}x_{t-1}, \beta_t I)$$

\textbf{Noise Schedule:}
\begin{itemize}
\item $\beta_t$ controls noise schedule
\item Linear: 0.0001 -> 0.02
\item Cosine: Variable rate
\item Matters: Smooth degradation
\end{itemize}

\column{0.48\textwidth}
\textbf{Reverse:}
$$p_\theta(x_{t-1}|x_t) = \mathcal{N}(\mu_\theta, \Sigma_\theta)$$

\textbf{Training:}
$$L = E[||\epsilon - \epsilon_\theta(x_t,t)||^2]$$

\textbf{Denoising objective:} Predict noise $\epsilon$, not image $x_0$

\textbf{Intuition:} Predict noise, subtract it
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Noise prediction objective enables stable training - predicting $\epsilon_\theta(x_t,t)$ instead of $x_0$ reduces variance, noise schedule controls diffusion speed (linear $\beta_t: 10^{-4} \to 2 \times 10^{-2}$ standard)
}
\end{frame}

% Slide 19: Visualization: Latent space interpolation
\begin{frame}
\frametitle{Latent Space Interpolation}
\framesubtitle{Smooth Transitions in Generated Content}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/latent_interpolation.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Method:}
\begin{itemize}
\item Sample $z_1, z_2$
\item Interpolate: $z_t = (1-t)z_1 + tz_2$
\item Generate: $x_t = G(z_t)$
\item Spherical interpolation: Better than linear for normalized spaces
\end{itemize}

\column{0.48\textwidth}
\textbf{Applications:}
\begin{itemize}
\item Style transfer
\item Face morphing
\item Molecule generation (drug discovery latent optimization)
\item Drug discovery
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Continuous latent spaces enable semantic interpolation - walking along manifold generates smooth transitions revealing learned structure organization and enabling controlled generation
}
\end{frame}

% Slide 20: Visualization: Denoising steps
\begin{frame}
\frametitle{Diffusion Denoising Visualization}
\framesubtitle{From Noise to Image in 1000 Steps}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/denoising_steps.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Steps:}
\begin{itemize}
\item T=1000: Noise
\item T=500: Structure
\item T=0: High quality
\item Controllable: Stop early for variations
\item DDIM (Song et al. 2020): 50 steps, 20x speedup
\end{itemize}

\column{0.48\textwidth}
\textbf{Control:}
\begin{itemize}
\item Guidance scale
\item Step count
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Progressive denoising reveals hierarchical generation - coarse structure emerges early (T=1000->500), fine details refine late (T=500->0), enabling quality-speed trade-offs
}
\end{frame}

% Slide 21: Why it works: Adversarial pressure forces realism
\begin{frame}
\frametitle{Why Adversarial Training Works}
\framesubtitle{The Mathematical Guarantee}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/adversarial_theory.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Theory:}
\begin{itemize}
\item Minimax convergence
\item Equilibrium: $p_g = p_{data}$
\item JS Divergence: Original GAN minimizes JS($p_{data} || p_g$)
\item Wasserstein: Modern GANs use Earth Mover distance (more stable)
\end{itemize}

\column{0.48\textwidth}
\textbf{Benefits:}
\begin{itemize}
\item Sharp, realistic
\item Fine details
\item No averaging
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Adversarial objective minimizes distributional divergence - discriminator estimates density ratio enabling generator gradient toward real data manifold, avoiding MSE's averaging through adversarial pressure
}
\end{frame}

% Slide 22: Experimental validation: Image quality metrics over time
\begin{frame}
\frametitle{Experimental Validation}
\framesubtitle{Quality Metrics vs Training Progress}

\begin{center}
\includegraphics[width=0.5\textwidth]{charts/quality_metrics_over_time.pdf}
\end{center}

\vspace{-0.3cm}
\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Results (MNIST):}
\scriptsize
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{IS} & \textbf{FID} & \textbf{Time} \\
\midrule
Random & 1.0 & 500 & - \\
VAE & 5.2 & 48 & 30min \\
GAN & 9.1 & 9 & 2hr \\
Diffusion & 9.3 & 3 & 8hr \\
Real & 9.7 & 0 & - \\
\bottomrule
\end{tabular}

\column{0.48\textwidth}
\textbf{Observations:}
\begin{itemize}
\item Diffusion: Best
\item GAN: 4x faster
\item VAE: Fast, blurry
\end{itemize}

\textbf{Patterns:}
\begin{itemize}
\item VAE: Monotonic
\item GAN: Oscillates
\end{itemize}

\textbf{Human baseline:}
\begin{itemize}
\item IS=9.8, FID=0.5 (perceptual comparison)
\end{itemize}
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Empirical validation confirms theoretical predictions - diffusion achieves best quality (FID=3), GAN balances quality-speed (FID=9, 4x faster), VAE trades quality for stability and speed
}
\end{frame}

% Slide 23: Implementation: Stable Diffusion API code
\begin{frame}[fragile]
\frametitle{Implementation: Stable Diffusion API}
\framesubtitle{Production-Ready Generative AI}

\begin{center}
\includegraphics[width=0.45\textwidth]{charts/stable_diffusion_api.pdf}
\end{center}

\footnotesize
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Usage:}
\begin{verbatim}
response = requests.post(
    api_url,
    headers={"Auth": key},
    json={
        "text_prompts": [{"text": "city"}],
        "cfg_scale": 7,
        "steps": 30
    })
\end{verbatim}

\column{0.48\textwidth}
\textbf{Parameters:}
\begin{itemize}
\item cfg scale: 1-20 (balance prompt adherence vs diversity)
\item steps: 10-150 (quality-speed trade-off: 10=fast/rough, 150=slow/perfect)
\end{itemize}

\textbf{Cost:} \$0.004/image
\end{columns}

\vspace{\fill}
\footnotesize \textcolor{gray}{
Production APIs abstract complexity - configuration parameters control guidance strength and quality-speed tradeoffs, enabling accessible deployment without deep technical expertise
}
\end{frame}