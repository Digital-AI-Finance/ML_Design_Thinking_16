% Part 2: Statistical Learning Theory
\section{Statistical Learning Theory}

% Section divider
\begin{frame}[plain]
\vfill
\centering
\begin{beamercolorbox}[sep=16pt,center]{title}
\usebeamerfont{title}\Large Part 2: Statistical Learning Theory\par
\vspace{0.5em}
\large Mathematical Foundations for Financial ML\par
\end{beamercolorbox}
\vfill
\end{frame}

% Probability Theory Review
\begin{frame}{Probability Theory: The Language of Uncertainty}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{Core Concepts}
\normalsize
\vspace{0.5em}

\textbf{Random Variable:}
$$X: \Omega \rightarrow \R$$

\textbf{Expectation:}
$$\E[X] = \int_{-\infty}^{\infty} x f_X(x) dx$$

\textbf{Variance:}
$$\Var[X] = \E[(X - \E[X])^2] = \E[X^2] - (\E[X])^2$$

\textbf{Covariance:}
$$\Cov(X,Y) = \E[(X-\mu_X)(Y-\mu_Y)]$$

\textbf{Correlation:}
$$\rho_{X,Y} = \frac{\Cov(X,Y)}{\sigma_X \sigma_Y}$$
\end{column}

\begin{column}{0.48\textwidth}
\Large\textbf{Financial Applications}
\normalsize
\vspace{0.5em}

\textbf{Return Distribution:}
$$R_t = \frac{P_t - P_{t-1}}{P_{t-1}} \sim \mathcal{N}(\mu, \sigma^2)$$

\textbf{Portfolio Variance:}
$$\sigma_p^2 = w^T\Sigma w$$
where $\Sigma$ is covariance matrix

\textbf{Value at Risk (95\%)}: 
$$\Prob(L > \text{VaR}_{0.95}) = 0.05$$

\textbf{Kelly Criterion:}
$$f^* = \frac{p(b+1) - 1}{b}$$
where $f^*$ = optimal fraction to bet
\end{column}
\end{columns}
\end{frame}

% Bayes Theorem
\begin{frame}{Bayes' Theorem: Updating Beliefs with Data}
\Large\textbf{Fundamental Formula}
\normalsize

$$\boxed{P(H|D) = \frac{P(D|H) \cdot P(H)}{P(D)}}$$

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\vspace{0.5em}
\textbf{Components:}
\begin{itemize}
\item $P(H)$: Prior probability
\item $P(D|H)$: Likelihood
\item $P(H|D)$: Posterior probability
\item $P(D)$: Evidence (normalizing constant)
\end{itemize}

\vspace{0.5em}
\textbf{Expanded Form:}
$$P(H_i|D) = \frac{P(D|H_i)P(H_i)}{\sum_j P(D|H_j)P(H_j)}$$
\end{column}

\begin{column}{0.48\textwidth}
\vspace{0.5em}
\textbf{Finance Example: Fraud Detection}

\begin{tcolorbox}[colback=finred!10, colframe=finred!50]
\small
Given:
\begin{itemize}
\item P(Fraud) = 0.001 (prior)
\item P(Alert|Fraud) = 0.95
\item P(Alert|Normal) = 0.02
\end{itemize}
Find: P(Fraud|Alert)

\vspace{0.3em}
Solution:
$$P(F|A) = \frac{0.95 \times 0.001}{0.95 \times 0.001 + 0.02 \times 0.999}$$
$$= \frac{0.00095}{0.02093} = 0.045 = 4.5\%$$
\end{tcolorbox}
\end{column}
\end{columns}
\end{frame}

% Statistical Inference
\begin{frame}{Statistical Inference: From Sample to Population}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{Maximum Likelihood}
\normalsize
\vspace{0.5em}

Given data $\mathcal{D} = \{x_1, ..., x_n\}$

\textbf{Likelihood Function:}
$$\mathcal{L}(\theta|\mathcal{D}) = \prod_{i=1}^n p(x_i|\theta)$$

\textbf{Log-Likelihood:}
$$\ell(\theta) = \sum_{i=1}^n \log p(x_i|\theta)$$

\textbf{MLE Estimate:}
$$\hat{\theta}_{MLE} = \argmax_\theta \ell(\theta)$$

\textbf{Example: Normal Returns}
$$\hat{\mu} = \frac{1}{n}\sum_{i=1}^n r_i$$
$$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (r_i - \hat{\mu})^2$$
\end{column}

\begin{column}{0.48\textwidth}
\Large\textbf{Bayesian Inference}
\normalsize
\vspace{0.5em}

\textbf{Posterior Distribution:}
$$p(\theta|\mathcal{D}) \propto p(\mathcal{D}|\theta) \cdot p(\theta)$$

\textbf{Conjugate Priors:}
\begin{itemize}
\item Beta-Binomial
\item Normal-Normal
\item Gamma-Poisson
\end{itemize}

\textbf{Black-Litterman Model:}
Combine market equilibrium (prior) with views (likelihood):

$$\E[R|\text{views}] = \left[(\tau\Sigma)^{-1} + P^T\Omega^{-1}P\right]^{-1}$$
$$\times \left[(\tau\Sigma)^{-1}\Pi + P^T\Omega^{-1}Q\right]$$
\end{column}
\end{columns}
\end{frame}

% PAC Learning
\begin{frame}{PAC Learning: Probably Approximately Correct}
\Large\textbf{Learning Guarantees}
\normalsize
\vspace{0.5em}

A learning algorithm is PAC if:

Given:
\begin{itemize}
\item Error parameter $\epsilon > 0$
\item Confidence parameter $\delta > 0$
\item Training sample size $m$
\end{itemize}

It outputs hypothesis $h$ such that:
$$\Prob[\text{error}(h) \leq \epsilon] \geq 1 - \delta$$

\vspace{0.5em}
\textbf{Sample Complexity Bound:}
$$m \geq \frac{1}{\epsilon}\left(\ln|\mathcal{H}| + \ln\frac{1}{\delta}\right)$$

where $|\mathcal{H}|$ is hypothesis space size

\vspace{0.5em}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Finance Interpretation:}
\begin{itemize}
\item $\epsilon$: Maximum tolerable error (e.g., 5\% mispricing)
\item $\delta$: Risk of failure (e.g., 1\% chance)
\item $m$: Required historical data
\end{itemize}
\end{column}

\begin{column}{0.48\textwidth}
\textbf{Example: Trading Strategy}
\begin{itemize}
\item Want: 95\% confidence
\item Max error: 2\%
\item Hypothesis space: 1000 strategies
\item Need: $m \geq \frac{1}{0.02}(\ln 1000 + \ln 100) \approx 689$ samples
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% VC Dimension
\begin{frame}{Vapnik-Chervonenkis (VC) Dimension}
\Large\textbf{Capacity of Learning Algorithms}
\normalsize
\vspace{0.5em}

\textbf{Definition:} The VC dimension of hypothesis class $\mathcal{H}$ is the maximum number of points that can be shattered (classified in all possible ways) by $\mathcal{H}$.

\vspace{0.5em}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Examples:}
\begin{itemize}
\item Linear classifiers in $\R^d$: VC = $d+1$
\item Decision trees depth $k$: VC $\approx 2^k$
\item Neural networks: VC $\propto$ \#parameters
\end{itemize}

\vspace{0.5em}
\textbf{Generalization Bound:}
With probability $1-\delta$:
$$R(h) \leq \hat{R}(h) + \sqrt{\frac{d(\ln(2m/d) + 1) + \ln(4/\delta)}{m}}$$

where:
\begin{itemize}
\item $R(h)$: True risk
\item $\hat{R}(h)$: Empirical risk
\item $d$: VC dimension
\end{itemize}
\end{column}

\begin{column}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{charts/vc_dimension.pdf}

\vspace{0.5em}
\textbf{Trading Strategy Complexity:}
\begin{itemize}
\item Simple MA crossover: VC $\approx$ 3
\item Multi-factor model: VC $\approx$ 20
\item Deep neural network: VC $\approx$ 10,000
\end{itemize}

\textcolor{finred}{\textbf{Warning:}} Higher VC = More overfitting risk!
\end{column}
\end{columns}
\end{frame}

% Information Theory
\begin{frame}{Information Theory in Machine Learning}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{Core Measures}
\normalsize
\vspace{0.5em}

\textbf{Entropy (Uncertainty):}
$$H(X) = -\sum_{x} p(x) \log_2 p(x)$$

\textbf{Cross-Entropy (Loss):}
$$H(p, q) = -\sum_{x} p(x) \log q(x)$$

\textbf{KL Divergence:}
$$D_{KL}(p||q) = \sum_{x} p(x) \log \frac{p(x)}{q(x)}$$

\textbf{Mutual Information:}
$$I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$$
\end{column}

\begin{column}{0.48\textwidth}
\Large\textbf{Finance Applications}
\normalsize
\vspace{0.5em}

\textbf{Portfolio Diversification:}
$$H(\text{portfolio}) = -\sum_{i} w_i \log w_i$$
Maximum entropy = equal weights

\textbf{Market Efficiency:}
$$I(\text{Signal}; \text{Returns}) \approx 0$$
Efficient markets have low MI

\textbf{Model Selection (AIC):}
$$AIC = 2k - 2\ln(\mathcal{L})$$
where $k$ = number of parameters

\textbf{Active Information Ratio:}
$$IR = \frac{\alpha}{\omega} = \sqrt{\text{Breadth} \times IC^2}$$
\end{column}
\end{columns}
\end{frame}

% More slides would continue for remaining topics...