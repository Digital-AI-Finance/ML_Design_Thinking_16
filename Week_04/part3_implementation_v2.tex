% Part 3: Implementation - Making It Work (12 slides)
\section{Part 3: Implementation - From Theory to Production}

% Slide 1: Pipeline - Data processing flow
\begin{frame}{Build Your Classification Pipeline}
\Large\textbf{From Raw Data to Predictions}
\normalsize

\vspace{0.5em}

\begin{center}
\begin{tikzpicture}[scale=0.8,
    box/.style={draw,rounded corners,fill=mlblue!20,minimum width=2.3cm,minimum height=0.7cm}]

% Pipeline stages with icons
\node[box,fill=mlred!20] (raw) at (0,0) {Raw Data};
\node[box,fill=mlorange!20] (clean) at (2.8,0) {Clean};
\node[box,fill=mlyellow!20] (encode) at (5.6,0) {Encode};
\node[box,fill=mlgreen!20] (scale) at (8.4,0) {Scale};
\node[box,fill=mlblue!20] (split) at (11.2,0) {Split};
\node[box,fill=mlpurple!20] (model) at (14,0) {Model};

% Arrows
\foreach \from/\to in {raw/clean,clean/encode,encode/scale,scale/split,split/model} {
    \draw[ultra thick,->] (\from) -- (\to);
}

% Details below each stage
\node[below,text width=2cm,align=center] at (0,-0.8) {\tiny Handle missing\\Outliers};
\node[below,text width=2cm,align=center] at (2.8,-0.8) {\tiny Fix types\\Validate};
\node[below,text width=2cm,align=center] at (5.6,-0.8) {\tiny One-hot\\Label};
\node[below,text width=2cm,align=center] at (8.4,-0.8) {\tiny Standard\\MinMax};
\node[below,text width=2cm,align=center] at (11.2,-0.8) {\tiny 80/20\\Stratified};
\node[below,text width=2cm,align=center] at (14,-0.8) {\tiny Train\\Predict};
\end{tikzpicture}
\end{center}

\vspace{0.5em}

\textbf{Python Implementation:}
\begin{small}
\texttt{from sklearn.pipeline import Pipeline} \\
\texttt{from sklearn.preprocessing import StandardScaler} \\
\texttt{from sklearn.model\_selection import train\_test\_split} \\
~\\
\texttt{pipeline = Pipeline([} \\
\texttt{~~~~('scaler', StandardScaler()),} \\
\texttt{~~~~('classifier', RandomForestClassifier())])}
\end{small}
\end{frame}

% Slide 2: Features - Engineering success indicators
\begin{frame}{Engineer Features That Matter}
\Large\textbf{Creating Meaningful Predictors}
\normalsize

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Raw → Engineered:}
\begin{itemize}
\item Date → Days since launch
\item Team size → Diversity index
\item Budget → Burn rate
\item Users → Growth rate
\item Reviews → Sentiment score
\end{itemize}

\vspace{0.5em}
\textbf{Feature Creation:}
\begin{small}
\texttt{df['efficiency'] =} \\
\texttt{~~~~df['output'] / df['cost']} \\
~\\
\texttt{df['momentum'] =} \\
\texttt{~~~~df['users'].pct\_change()}
\end{small}
\end{column}
\begin{column}{0.48\textwidth}
\begin{center}
\includegraphics[width=0.85\textwidth]{charts/innovation_multiclass_analysis.pdf}
\end{center}

Feature importance changes by class
\end{column}
\end{columns}
\end{frame}

% Slide 3: Validation - Robust evaluation
\begin{frame}{Validate Like a Pro}
\Large\textbf{Cross-Validation for Robust Results}
\normalsize

\vspace{0.5em}

\begin{center}
\includegraphics[width=0.8\textwidth]{charts/cross_validation_comparison.pdf}
\end{center}

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{K-Fold Strategy:}
\begin{itemize}
\item Split data into 5 folds
\item Train on 4, test on 1
\item Rotate and average
\item Get confidence intervals
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Why It Matters:}
\begin{itemize}
\item Single split = lucky/unlucky
\item Cross-validation = true performance
\item Shows model stability
\item Reveals overfitting
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 4: Tuning - Hyperparameter optimization
\begin{frame}{Find Your Model's Sweet Spot}
\Large\textbf{Hyperparameter Tuning}
\normalsize

\vspace{0.5em}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/hyperparameter_sensitivity.pdf}
\end{center}

\vspace{0.5em}

\textbf{Grid Search Implementation:}
\begin{small}
\texttt{param\_grid = \{'n\_estimators': [50, 100, 200],} \\
\texttt{~~~~~~~~~~~~~'max\_depth': [5, 10, None]\}} \\
\texttt{grid = GridSearchCV(RandomForestClassifier(), param\_grid, cv=5)} \\
\texttt{grid.fit(X\_train, y\_train)} \\
\texttt{best\_model = grid.best\_estimator\_}
\end{small}
\end{frame}

% Slide 5: Selection - Choosing the right model
\begin{frame}{Choose the Right Tool for the Job}
\Large\textbf{Model Selection Criteria}
\normalsize

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.55\textwidth}
\includegraphics[width=0.85\textwidth]{charts/innovation_algorithm_comparison.pdf}
\end{column}
\begin{column}{0.43\textwidth}
\textbf{Decision Factors:}
\begin{enumerate}
\item Accuracy needs
\item Speed requirements
\item Interpretability
\item Data volume
\item Deployment constraints
\end{enumerate}

\vspace{0.5em}
\textbf{Business Questions:}
\begin{itemize}
\item Real-time or batch?
\item Cloud or edge?
\item Explainable or black-box?
\item Retraining frequency?
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 6: Learning curves - Diagnosing behavior
\begin{frame}{Diagnose Your Model's Health}
\Large\textbf{Learning Curves Tell the Story}
\normalsize

\vspace{0.5em}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/learning_curves_comparison.pdf}
\end{center}

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.32\textwidth}
\textbf{Underfitting:}
\begin{itemize}
\small
\item Both curves low
\item Add complexity
\item More features
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{Good Fit:}
\begin{itemize}
\small
\item Curves converge
\item Small gap
\item Ready to deploy
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{Overfitting:}
\begin{itemize}
\small
\item Large gap
\item Regularize
\item More data
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 7: Optimization - Speed and scale
\begin{frame}{Make It Fast, Make It Scale}
\Large\textbf{Performance Optimization}
\normalsize

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Training Speed:}
\begin{itemize}
\item Use all CPU cores: \texttt{n\_jobs=-1}
\item Sample for prototyping
\item Early stopping
\item Incremental learning
\end{itemize}

\vspace{0.5em}
\textbf{Prediction Speed:}
\begin{itemize}
\item Cache predictions
\item Batch processing
\item Model compression
\item Feature selection
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Benchmarks Achieved:}
\begin{itemize}
\item Training: 2.3s → 0.8s
\item Prediction: 120ms → 15ms
\item Memory: 4GB → 1.2GB
\item Throughput: 100/s → 1000/s
\end{itemize}

\vspace{0.5em}
\textbf{Code Optimization:}
\begin{small}
\texttt{rf = RandomForestClassifier(} \\
\texttt{~~~~n\_estimators=100,} \\
\texttt{~~~~n\_jobs=-1,  \# Parallel} \\
\texttt{~~~~max\_depth=10  \# Limit} \\
\texttt{)}
\end{small}
\end{column}
\end{columns}
\end{frame}

% Slide 8: Deployment - From notebook to production
\begin{frame}{Deploy to the Real World}
\Large\textbf{From Notebook to Production}
\normalsize

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Save Your Model:}
\begin{small}
\texttt{import joblib} \\
~\\
\texttt{\# Train and save} \\
\texttt{model.fit(X\_train, y\_train)} \\
\texttt{joblib.dump(model, 'model.pkl')} \\
~\\
\texttt{\# Load and predict} \\
\texttt{model = joblib.load('model.pkl')} \\
\texttt{prediction = model.predict(X\_new)}
\end{small}

\vspace{0.5em}
\textbf{Deployment Options:}
\begin{itemize}
\item Flask/FastAPI
\item Docker containers
\item Cloud services
\item Serverless functions
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Production Checklist:}
\begin{itemize}
\item[$\square$] Input validation
\item[$\square$] Error handling
\item[$\square$] Logging setup
\item[$\square$] Monitoring metrics
\item[$\square$] Version control
\item[$\square$] Rollback plan
\item[$\square$] A/B testing
\item[$\square$] Documentation
\end{itemize}

\vspace{0.5em}
\textbf{Architecture:}
\begin{center}
API → Model Server → Cache → Database
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 9: Monitoring - Keeping models healthy
\begin{frame}{Keep Your Model Healthy}
\Large\textbf{Monitoring \& Maintenance}
\normalsize

\vspace{0.5em}

\begin{center}
\begin{tikzpicture}[scale=0.8,
    box/.style={draw,rounded corners,fill=mlblue!20,minimum width=2.5cm,minimum height=0.8cm}]

% Monitoring cycle
\node[box,fill=mlgreen!20] (predict) at (0,2) {Predict};
\node[box,fill=mlyellow!20] (monitor) at (3,0) {Monitor};
\node[box,fill=mlorange!20] (alert) at (0,-2) {Alert};
\node[box,fill=mlred!20] (retrain) at (-3,0) {Retrain};

% Arrows
\draw[thick,->] (predict) -- (monitor) node[midway,above right] {\small metrics};
\draw[thick,->] (monitor) -- (alert) node[midway,below right] {\small drift};
\draw[thick,->] (alert) -- (retrain) node[midway,below left] {\small trigger};
\draw[thick,->] (retrain) -- (predict) node[midway,above left] {\small update};

% Center label
\node at (0,0) {\textbf{Continuous}};
\node at (0,-0.4) {\textbf{Improvement}};
\end{tikzpicture}
\end{center}

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{What to Monitor:}
\begin{itemize}
\item Accuracy over time
\item Prediction distribution
\item Feature distributions
\item Response times
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{When to Retrain:}
\begin{itemize}
\item Performance drops 5\%
\item New data patterns
\item Business rules change
\item Quarterly schedule
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 10: Pitfalls - Common mistakes
\begin{frame}{Avoid These Rookie Mistakes}
\Large\textbf{Common Pitfalls and Solutions}
\normalsize

\vspace{0.5em}

\begin{center}
\begin{tabular}{p{4.5cm}p{6.5cm}}
\toprule
\textbf{Pitfall} & \textbf{Solution} \\
\midrule
Data leakage &
Split before any preprocessing \\
\addlinespace
Overfitting to training &
Always use cross-validation \\
\addlinespace
Ignoring imbalance &
Use appropriate metrics \& techniques \\
\addlinespace
Wrong metric for problem &
Match metric to business need \\
\addlinespace
No monitoring in production &
Set up alerts from day 1 \\
\bottomrule
\end{tabular}
\end{center}

\vspace{1em}
\begin{center}
\Large\textit{``Learn from others' expensive mistakes''}
\end{center}
\end{frame}

% Slide 11: Case Study - Complete example
\begin{frame}{Real Success Story}
\Large\textbf{Startup Success Predictor in Action}
\normalsize

\vspace{0.5em}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{The Challenge:}
\begin{itemize}
\item VC evaluating 1000+ startups/year
\item 2\% historical success rate
\item \$500K average investment
\item 6 month decision process
\end{itemize}

\vspace{0.5em}
\textbf{The Solution:}
\begin{itemize}
\item 10 years of data (5000 startups)
\item 47 features engineered
\item Gradient Boosting model
\item 89\% accuracy achieved
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Results:}
\begin{center}
\begin{tikzpicture}[scale=0.7]
\begin{axis}[
    ybar,
    ylabel={Success Rate (\%)},
    symbolic x coords={Before,After},
    xtick=data,
    nodes near coords,
    ymin=0, ymax=10,
    width=7cm,
    height=5cm
]
\addplot[fill=mlred!60] coordinates {(Before,2)};
\addplot[fill=mlgreen!60] coordinates {(After,7.5)};
\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Impact:}
\begin{itemize}
\item 3.75x better success rate
\item 50\% time saved
\item \$120M additional returns
\item More diverse portfolio
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 12: Transition - To design
\begin{frame}{Ready for Users?}
\Large\textbf{From Systems to People}
\normalsize

\vspace{1em}

\begin{center}
You've built a powerful classifier that:
\begin{itemize}
\item Processes data efficiently
\item Makes accurate predictions
\item Scales to production
\item Monitors itself
\end{itemize}

\vspace{1em}
\Huge\textbf{Now make it usable!}

\vspace{1em}
\begin{tikzpicture}
\draw[ultra thick,->,mlpurple] (0,0) -- (4,0);
\node[above] at (2,0.2) {\Large Next: Part 4 - Design Integration};
\end{tikzpicture}

\vspace{1em}
\Large\textit{``Technology is only as good as its interface''}
\end{center}
\end{frame}