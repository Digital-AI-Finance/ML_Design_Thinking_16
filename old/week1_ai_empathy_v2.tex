\documentclass[8pt,aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{adjustbox}
\usepackage{colortbl}

% Theme
\usetheme{Madrid}
\usecolortheme{seahorse}
\setbeamertemplate{navigation symbols}{}

% Colors
\definecolor{myblue}{RGB}{0,102,204}
\definecolor{mygreen}{RGB}{0,153,76}
\definecolor{myred}{RGB}{204,0,0}
\definecolor{lightblue}{RGB}{173,216,230}
\definecolor{darkgray}{RGB}{64,64,64}

% Commands
\newcommand{\highlight}[1]{\textcolor{myblue}{\textbf{#1}}}
\newcommand{\concept}[1]{\textcolor{mygreen}{\texttt{#1}}}
\newcommand{\emphred}[1]{\textcolor{myred}{\textbf{#1}}}
\newcommand{\term}[1]{\textbf{#1}\footnote{See glossary}}

% Footnote size
\renewcommand{\footnotesize}{\tiny}

\title{Week 1: AI as the Empathy Engine}
\subtitle{How ML/AI/GenAI Drives Understanding at Scale}
\author{ML/AI/GenAI-Driven Design Thinking}
\date{}

\begin{document}

% Title Slide
\begin{frame}
\titlepage
\end{frame}

% Course Overview
\begin{frame}[t]{Course Roadmap}
\begin{center}
\textbf{Where We Are in the 12-Week Journey}
\vspace{0.5em}

\begin{tabular}{|c|c|c|c|}
\hline
\cellcolor{myblue}\textcolor{white}{\textbf{Week 1}} & Week 2 & Week 3 & Week 4 \\
\textbf{Empathy} & Personas & Problems & Ideation \\
\hline
Week 5 & Week 6 & Week 7 & Week 8 \\
Prototyping & Testing & Optimization & Personalization \\
\hline
Week 9 & Week 10 & Week 11 & Week 12 \\
Ethics & Systems & Evolution & Future \\
\hline
\end{tabular}
\end{center}

\vspace{0.5em}
\textbf{Today's Focus}: How AI transforms understanding users from dozens to millions
\end{frame}

% Learning Objectives
\begin{frame}[t]{Today's Learning Objectives}
\Large
\textbf{By the end of today, you will understand:}
\vspace{0.5em}

\normalsize
\begin{enumerate}
\setlength{\itemsep}{0.8em}
\item How AI discovers \highlight{hidden patterns} in user data
\item The power of \highlight{scale} - from 10 to 1,000,000 users
\item \highlight{NLP} techniques that process text automatically
\item How \highlight{GenAI} creates user narratives
\item The \highlight{speed} advantage - weeks to hours
\end{enumerate}

\vspace{1em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Key Transformation}: Manual empathy $\rightarrow$ Automated understanding
\end{tcolorbox}
\end{frame}

% Section 1: Introduction
\begin{frame}[c]
\begin{center}
\Huge\textbf{Section 1}\\
\vspace{0.5em}
\Large\textcolor{myblue}{The Paradigm Shift}\\
\vspace{0.3em}
\normalsize From Manual to Machine Understanding
\end{center}
\end{frame}

% The Big Picture
\begin{frame}[t]{The Empathy Revolution}
\begin{center}
\Large\textbf{Traditional Design Thinking}\\
\normalsize Interview 20 people $\rightarrow$ Find patterns $\rightarrow$ Design solutions\\
\vspace{1em}
\Large\textbf{AI-Driven Design Thinking}\\
\normalsize Analyze 1M+ data points $\rightarrow$ Discover patterns $\rightarrow$ Personalize solutions
\end{center}

\vspace{1em}
\begin{tcolorbox}[colback=lightblue!20]
\centering
\textbf{Key Insight}: AI doesn't replace empathy - it \emphred{amplifies} it
\end{tcolorbox}
\end{frame}

% Comparison Chart
\begin{frame}[t]{The Scale Advantage}
\begin{center}
\includegraphics[width=0.9\textwidth]{charts/comparison_chart.pdf}
\end{center}

\textbf{What this means}:
\begin{itemize}
\item 5,000x more users reached
\item 35x faster analysis
\item 25x more insights generated
\item 80\% cost reduction
\end{itemize}
\end{frame}

% Scale Visualization
\begin{frame}[t]{Understanding Scale}
\begin{center}
\includegraphics[width=0.9\textwidth]{charts/scale_visualization.pdf}
\end{center}

\begin{tcolorbox}[colback=lightblue!20]
\textbf{Remember}: Each circle represents real people with real needs
\end{tcolorbox}
\end{frame}

% What is Empathy
\begin{frame}[t]{What is Empathy in Design?}
\Large
\textbf{Empathy}\footnote{Understanding user feelings and needs} means:
\vspace{0.5em}

\normalsize
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Traditional Approach:}
\begin{itemize}
\item Face-to-face interviews
\item Observation sessions
\item Diary studies
\item Focus groups
\end{itemize}

\column{0.5\textwidth}
\textbf{AI-Enhanced Approach:}
\begin{itemize}
\item Text analysis at scale
\item Behavior pattern detection
\item Sentiment tracking
\item Predictive modeling
\end{itemize}
\end{columns}

\vspace{1em}
\begin{center}
\textbf{Both approaches seek the same goal}: \highlight{Understanding users deeply}
\end{center}
\end{frame}

% Section 2: Pattern Recognition
\begin{frame}[c]
\begin{center}
\Huge\textbf{Section 2}\\
\vspace{0.5em}
\Large\textcolor{myblue}{Pattern Recognition at Scale}\\
\vspace{0.3em}
\normalsize How ML Discovers What Humans Can't See
\end{center}
\end{frame}

% What are Patterns
\begin{frame}[t]{What Are Patterns?}
\textbf{Patterns are regularities in data that reveal insights}

\vspace{0.5em}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Simple Patterns:}
\begin{itemize}
\item Users complain about speed
\item Login fails on mobile
\item Peak usage at 7 PM
\end{itemize}

\column{0.5\textwidth}
\textbf{Complex Patterns:}
\begin{itemize}
\item Frustration correlates with 3+ clicks
\item Cultural differences in navigation
\item Emotional journey through app
\end{itemize}
\end{columns}

\vspace{1em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{ML Advantage}: Can find patterns across millions of interactions simultaneously
\end{tcolorbox}
\end{frame}

% Pattern Heatmap
\begin{frame}[t]{AI-Discovered Pattern Map}
\begin{center}
\includegraphics[width=0.85\textwidth]{charts/pattern_heatmap.pdf}
\end{center}

\textbf{Reading this chart}: Darker = Stronger pattern
\begin{itemize}
\item Power users need less support but want features
\item New users need help but don't report errors
\item Churning users show high error rates
\end{itemize}
\end{frame}

% How ML Finds Patterns
\begin{frame}[t]{How Does ML Find Patterns?}
\Large\textbf{The Process:}
\normalsize
\vspace{0.5em}

\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item \textbf{Collect Data}: Reviews, clicks, surveys, support tickets
\item \textbf{Clean \& Prepare}: Remove noise, standardize format
\item \textbf{Extract Features}\footnote{Measurable properties}: Time, frequency, sentiment
\item \textbf{Apply Algorithms}: Clustering\footnote{Grouping similar items}, classification\footnote{Predicting categories}
\item \textbf{Validate Findings}: Check against known truths
\end{enumerate}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Key Point}: ML can process 100,000 reviews in the time it takes to read 10
\end{tcolorbox}
\end{frame}

% Accuracy Comparison
\begin{frame}[t]{Human vs Machine Pattern Detection}
\begin{center}
\includegraphics[width=0.9\textwidth]{charts/accuracy_table.pdf}
\end{center}

\textbf{Why machines excel}:
\begin{itemize}
\item No fatigue or bias
\item Consistent criteria
\item Can hold entire dataset in "memory"
\end{itemize}
\end{frame}

% Section 3: From Data to Insights
\begin{frame}[c]
\begin{center}
\Huge\textbf{Section 3}\\
\vspace{0.5em}
\Large\textcolor{myblue}{From Data to Insights}\\
\vspace{0.3em}
\normalsize The NLP Pipeline That Drives Understanding
\end{center}
\end{frame}

% NLP Pipeline
\begin{frame}[t]{The NLP Processing Pipeline}
\begin{center}
\includegraphics[width=0.95\textwidth]{charts/nlp_pipeline.pdf}
\end{center}
\end{frame}

% What is NLP
\begin{frame}[t]{Natural Language Processing Explained}
\textbf{NLP}\footnote{Teaching computers to understand human language} enables:

\vspace{0.5em}
\begin{itemize}
\setlength{\itemsep}{0.5em}
\item \textbf{Sentiment Analysis}: Is this review positive or negative?
\item \textbf{Topic Modeling}: What are users talking about?
\item \textbf{Entity Recognition}: Finding names, dates, products
\item \textbf{Intent Detection}: What does the user want?
\item \textbf{Summarization}: Key points from 1000 reviews
\end{itemize}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Example}: "The app crashes constantly on my iPhone 12" \\
$\rightarrow$ Negative sentiment, Topic: stability, Entity: iPhone 12
\end{tcolorbox}
\end{frame}

% Topic Clustering
\begin{frame}[t]{Automatic Topic Discovery}
\begin{center}
\includegraphics[width=0.85\textwidth]{charts/topic_clustering.pdf}
\end{center}

\textbf{What happened here}:
\begin{itemize}
\item 10,000 comments analyzed
\item 5 main topics emerged automatically
\item No human categorization needed
\end{itemize}
\end{frame}

% Timeline Comparison
\begin{frame}[t]{Speed: The Game Changer}
\begin{center}
\includegraphics[width=0.95\textwidth]{charts/timeline_comparison.pdf}
\end{center}
\end{frame}

% Section 4: AI as Creative Partner
\begin{frame}[c]
\begin{center}
\Huge\textbf{Section 4}\\
\vspace{0.5em}
\Large\textcolor{myblue}{AI as Creative Partner}\\
\vspace{0.3em}
\normalsize Generative AI for Synthesis and Storytelling
\end{center}
\end{frame}

% What is GenAI
\begin{frame}[t]{Generative AI: From Data to Stories}
\textbf{GenAI}\footnote{AI that creates new content} transforms numbers into narratives

\vspace{0.5em}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Input:}
\begin{itemize}
\item Cluster of 500 users
\item Age: 25-35
\item Behavior: Quick tasks
\item Pain: Multiple steps
\end{itemize}

\column{0.5\textwidth}
\textbf{Output:}
\begin{quote}
"Meet Sarah, a busy professional who uses the app during commute. She needs one-tap solutions..."
\end{quote}
\end{columns}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Power}: GenAI creates relatable personas from statistical clusters
\end{tcolorbox}
\end{frame}

% How LLMs Work
\begin{frame}[t]{How Large Language Models Work}
\textbf{Simplified Explanation:}

\vspace{0.5em}
\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item \textbf{Training}: Read billions of documents
\item \textbf{Learning}: Understand patterns in language
\item \textbf{Predicting}: Generate likely next words
\item \textbf{Creating}: Combine patterns in new ways
\end{enumerate}

\vspace{0.5em}
\textbf{For Design Thinking}:
\begin{itemize}
\item Summarize user feedback
\item Generate persona narratives
\item Suggest problem framings
\item Brainstorm solutions
\end{itemize}

\begin{tcolorbox}[colback=lightblue!20]
\textbf{Remember}: LLMs are tools, not replacements for human creativity
\end{tcolorbox}
\end{frame}

% Empathy Funnel
\begin{frame}[t]{The AI Empathy Funnel}
\begin{center}
\includegraphics[width=0.85\textwidth]{charts/empathy_funnel.pdf}
\end{center}
\end{frame}

% Section 5: Implementation
\begin{frame}[c]
\begin{center}
\Huge\textbf{Section 5}\\
\vspace{0.5em}
\Large\textcolor{myblue}{Implementation \& Ethics}\\
\vspace{0.3em}
\normalsize Putting AI Empathy into Practice
\end{center}
\end{frame}

% Implementation Steps
\begin{frame}[t]{How to Start Using AI for Empathy}
\textbf{5-Step Process:}

\vspace{0.5em}
\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item \textbf{Gather Data}
  \begin{itemize}
  \item Reviews, surveys, support tickets
  \item Ensure diverse representation
  \end{itemize}
  
\item \textbf{Choose Tools}
  \begin{itemize}
  \item Python for analysis
  \item ChatGPT/Claude for synthesis
  \end{itemize}
  
\item \textbf{Process \& Analyze}
  \begin{itemize}
  \item Clean data, run NLP
  \item Find patterns, cluster users
  \end{itemize}
  
\item \textbf{Generate Insights}
  \begin{itemize}
  \item Create personas, find pain points
  \item Prioritize by impact
  \end{itemize}
  
\item \textbf{Validate}
  \begin{itemize}
  \item Check with real users
  \item Iterate and improve
  \end{itemize}
\end{enumerate}
\end{frame}

% Ethical Considerations
\begin{frame}[t]{Ethical Considerations}
\textbf{Critical Questions to Ask:}

\vspace{0.5em}
\begin{itemize}
\setlength{\itemsep}{0.5em}
\item \emphred{Representation}: Whose voices are in the data?
\item \emphred{Privacy}: How is user data protected?
\item \emphred{Bias}: What biases exist in our algorithms?
\item \emphred{Transparency}: Do users know how we analyze them?
\item \emphred{Benefit}: Are we helping or exploiting?
\end{itemize}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Golden Rule}: Use AI to understand users better, not manipulate them
\end{tcolorbox}
\end{frame}

% Case Study
\begin{frame}[t]{Case Study: Spotify's Success}
\textbf{How Spotify Uses AI for Empathy:}

\vspace{0.5em}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Data Scale:}
\begin{itemize}
\item 500M+ users
\item 100M songs daily
\item Billions of interactions
\end{itemize}

\column{0.5\textwidth}
\textbf{AI Insights:}
\begin{itemize}
\item Mood patterns
\item Music discovery preferences
\item Cultural taste differences
\end{itemize}
\end{columns}

\vspace{0.5em}
\textbf{Result}: Discover Weekly - personalized playlists that feel "magical"

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Success Factor}: AI understands individual users through population patterns
\end{tcolorbox}
\end{frame}

% Common Pitfalls
\begin{frame}[t]{Common Pitfalls to Avoid}
\textbf{Don't make these mistakes:}

\vspace{0.5em}
\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item \emphred{Over-trusting AI}
  \begin{itemize}
  \item Always validate with real users
  \end{itemize}
  
\item \emphred{Ignoring edge cases}
  \begin{itemize}
  \item ML focuses on majority patterns
  \end{itemize}
  
\item \emphred{Losing human touch}
  \begin{itemize}
  \item Data complements, doesn't replace, human insight
  \end{itemize}
  
\item \emphred{Analysis paralysis}
  \begin{itemize}
  \item More data isn't always better
  \end{itemize}
  
\item \emphred{Forgetting context}
  \begin{itemize}
  \item Numbers need human interpretation
  \end{itemize}
\end{enumerate}
\end{frame}

% Tools and Resources
\begin{frame}[t]{Tools You Can Use Today}
\begin{columns}[T]
\column{0.5\textwidth}
\textbf{Free Tools:}
\begin{itemize}
\item Google Colab (Python)
\item ChatGPT (synthesis)
\item Kaggle (datasets)
\item Orange (visual ML)
\end{itemize}

\column{0.5\textwidth}
\textbf{Python Libraries:}
\begin{itemize}
\item pandas (data)
\item scikit-learn (ML)
\item NLTK (text)
\item matplotlib (charts)
\end{itemize}
\end{columns}

\vspace{1em}
\textbf{Start Simple:}
\begin{enumerate}
\item Analyze 100 reviews with sentiment analysis
\item Create clusters from user data
\item Generate personas with ChatGPT
\end{enumerate}

\begin{tcolorbox}[colback=lightblue!20]
\textbf{Tip}: You don't need to be a programmer - many tools are no-code!
\end{tcolorbox}
\end{frame}

% Summary
\begin{frame}[t]{Key Takeaways}
\Large\textbf{What We Learned Today:}
\normalsize
\vspace{0.5em}

\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item AI enables understanding at \highlight{massive scale}
\item ML finds \highlight{hidden patterns} humans miss
\item NLP processes text \highlight{180x faster}
\item GenAI creates \highlight{narratives from data}
\item Ethics and validation remain \highlight{critical}
\end{enumerate}

\vspace{0.5em}
\begin{tcolorbox}[colback=mygreen!20]
\centering
\textbf{Remember}: AI amplifies empathy, it doesn't replace it
\end{tcolorbox}
\end{frame}

% Practice Exercise
\begin{frame}[t]{Your Turn: Practice Exercise}
\textbf{Mini-Project for This Week:}

\vspace{0.5em}
\begin{enumerate}
\setlength{\itemsep}{0.5em}
\item \textbf{Find}: 50-100 product reviews online
\item \textbf{Analyze}: 
  \begin{itemize}
  \item Manually read 10 reviews
  \item Use any text analysis tool for all 100
  \end{itemize}
\item \textbf{Compare}:
  \begin{itemize}
  \item What patterns did you find manually?
  \item What did the tool discover?
  \item What did you miss?
  \end{itemize}
\item \textbf{Create}: One data-driven persona using findings
\end{enumerate}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Goal}: Experience the power of scale firsthand
\end{tcolorbox}
\end{frame}

% Questions to Ponder
\begin{frame}[t]{Questions to Ponder}
\Large\textbf{Think About:}
\normalsize
\vspace{1em}

\begin{itemize}
\setlength{\itemsep}{0.8em}
\item If we can understand millions of users, how do we prioritize?
\item What aspects of empathy can never be automated?
\item How might AI empathy change in 5 years?
\item What are the risks of "knowing too much" about users?
\item How do we maintain human connection at scale?
\end{itemize}

\vspace{1em}
\begin{center}
\textbf{Discuss these with your peers!}
\end{center}
\end{frame}

% Next Week Preview
\begin{frame}[t]{Next Week: Data-Driven Personas}
\textbf{Week 2 Preview:}

\vspace{0.5em}
\begin{itemize}
\setlength{\itemsep}{0.5em}
\item How clustering creates personas automatically
\item Dynamic personas that evolve
\item From 5 personas to 5,000 micro-personas
\item Validation techniques
\item GenAI for persona narratives
\end{itemize}

\vspace{1em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Preparation}: Think about how you currently create personas
\end{tcolorbox}

\vspace{0.5em}
\begin{center}
\Large\textbf{See you next week!}
\end{center}
\end{frame}

% References
\begin{frame}[t]{Want to Learn More?}
\textbf{Recommended Resources:}

\vspace{0.5em}
\begin{itemize}
\setlength{\itemsep}{0.3em}
\item \textbf{Book}: "Weapons of Math Creation" - How big data increases inequality
\item \textbf{Course}: Andrew Ng's Machine Learning Course (Coursera)
\item \textbf{Tool}: Google's "What-If Tool" for ML exploration
\item \textbf{Paper}: "Attention Is All You Need" (Transformer architecture)
\item \textbf{Blog}: "The Illustrated Transformer" by Jay Alammar
\item \textbf{Practice}: Kaggle competitions for hands-on experience
\end{itemize}

\vspace{0.5em}
\begin{tcolorbox}[colback=lightblue!20]
\textbf{Remember}: The glossary appendix has all term definitions!
\end{tcolorbox}
\end{frame}

\end{document}