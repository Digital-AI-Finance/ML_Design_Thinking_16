\documentclass[8pt,aspectratio=169]{beamer}
\usetheme{Madrid}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning}

% Define colors matching the overview presentation
\definecolor{mlblue}{RGB}{31, 119, 180}
\definecolor{mlorange}{RGB}{255, 127, 14}
\definecolor{mlgreen}{RGB}{44, 160, 44}
\definecolor{mlred}{RGB}{214, 39, 40}
\definecolor{mlpurple}{RGB}{148, 103, 189}
\definecolor{mlbrown}{RGB}{140, 86, 75}
\definecolor{mlpink}{RGB}{227, 119, 194}
\definecolor{mlgray}{RGB}{127, 127, 127}
\definecolor{mlyellow}{RGB}{255, 187, 120}
\definecolor{mlcyan}{RGB}{23, 190, 207}

% Remove navigation symbols
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

\title{\Large\textbf{Machine Learning for Smarter Innovation}\\
\vspace{0.5em}
\Large Week 1: Foundations \& Clustering}
\subtitle{Discovering Innovation Patterns with ML}
\author{BSc Course in AI-Enhanced Innovation}
\date{}

\begin{document}

% Title slide
\begin{frame}
\titlepage
\end{frame}

% Slide 2: Course Overview - The Innovation Trinity
\begin{frame}
\frametitle{\Large Machine Learning + Innovation + Design Thinking}
\framesubtitle{The Power of Convergent Methodologies}

\begin{center}
\includegraphics[width=0.85\textwidth]{../ML_Design_Course/course_visuals/unified_pipeline.pdf}
\end{center}

\begin{center}
\Large\textcolor{mlpurple}{\textbf{Where Data Science Meets Human Creativity}}\\
\vspace{0.5em}
\normalsize Three powerful forces converge to amplify innovation impact
\end{center}
\end{frame}

% PART 1 SECTION DIVIDER
\begin{frame}[plain]
\begin{center}
\vspace{2em}
\Large\textcolor{mlblue}{\textbf{PART 1}}\\
\vspace{0.5em}
\Large\textbf{Foundation \& Context}\\
\vspace{2em}
\Large
What we'll explore:\\
\vspace{1em}
\normalsize
\begin{itemize}
\item Why traditional design hits limits
\item How ML amplifies human insight
\item The dual pipeline approach
\item Your learning journey ahead
\end{itemize}
\vspace{2em}
\Large\textcolor{mlpurple}{\textbf{Setting the stage for transformation}}
\end{center}
\end{frame}

% PART 1: FOUNDATION & CONTEXT (8 slides)

% Slide 3: The Innovation Challenge
\begin{frame}
\frametitle{\Large The Innovation Challenge}
\framesubtitle{Why Traditional Design Needs AI Enhancement}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlred!10, colframe=mlred!50, title=Traditional Design Limits]
\begin{itemize}
\item \textbf{Scale}: Can analyze 50 ideas, not 50,000
\item \textbf{Speed}: Months for insights
\item \textbf{Bias}: Designer's perspective dominates
\item \textbf{Patterns}: Miss hidden connections
\item \textbf{Iteration}: Slow feedback loops
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50, title=AI-Enhanced Innovation]
\begin{itemize}
\item \textbf{Scale}: Analyze millions of data points
\item \textbf{Speed}: Real-time insights
\item \textbf{Objectivity}: Data-driven discovery
\item \textbf{Patterns}: Find non-obvious relationships
\item \textbf{Iteration}: Continuous learning
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{The Promise: 100x more insights, 10x faster innovation}}
\end{center}
\end{frame}

% Slide 4: The Dual Pipeline Chart
\begin{frame}
\frametitle{\Large The Dual Pipeline}
\framesubtitle{Where ML Meets Design Thinking}

\begin{center}
\includegraphics[width=0.85\textwidth]{../ML_Design_Course/course_visuals/dual_pipeline.pdf}
\end{center}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{Two Powerful Methodologies Converge}}
\end{center}
\end{frame}

% Slide 5: The Dual Pipeline Comparison
\begin{frame}
\frametitle{\Large The Dual Pipeline (Continued)}
\framesubtitle{Understanding Both Worlds}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50, title=ML Pipeline]
\normalsize
\textbf{Data} $\rightarrow$ \textbf{Preprocess} $\rightarrow$ \textbf{Model} $\rightarrow$ \textbf{Evaluate} $\rightarrow$ \textbf{Deploy}
\vspace{0.3em}
\begin{itemize}
\item Collect innovation data
\item Clean and transform
\item Train algorithms
\item Validate accuracy
\item Scale to production
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Design Pipeline]
\normalsize
\textbf{Empathize} $\rightarrow$ \textbf{Define} $\rightarrow$ \textbf{Ideate} $\rightarrow$ \textbf{Prototype} $\rightarrow$ \textbf{Test}
\vspace{0.3em}
\begin{itemize}
\item Understand innovation needs
\item Frame problems
\item Generate solutions
\item Build concepts
\item Validate innovation impact
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{Integration = Innovation at Scale}}
\end{center}
\end{frame}

% Slide 6: Your Innovation Journey Chart
\begin{frame}
\frametitle{\Large Your Innovation Journey}
\framesubtitle{10 Weeks to AI-Powered Design Mastery}

\begin{center}
\includegraphics[width=0.85\textwidth]{../ML_Design_Course/course_visuals/journey_roadmap.pdf}
\end{center}
\end{frame}

% Slide 7: Your Innovation Journey Details
\begin{frame}
\frametitle{\Large Your Innovation Journey (Continued)}
\framesubtitle{What You'll Master in Each Stage}

\begin{center}
\Large
\begin{tabular}{lll}
\toprule
\textbf{Stage} & \textbf{Weeks} & \textbf{Innovation Unlocked} \\
\midrule
\textcolor{mlpurple}{Empathize} & 1-2 & Discover hidden innovation opportunities \\
\textcolor{mlblue}{Define} & 3-4 & Identify the right problems to solve \\
\textcolor{mlgreen}{Ideate} & 5-6 & Generate novel solutions with AI \\
\textcolor{mlorange}{Prototype} & 7-8 & Build smart, adaptive concepts \\
\textcolor{mlred}{Test} & 9-10 & Evolve through continuous learning \\
\bottomrule
\end{tabular}
\end{center}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{This Week: Clustering for Innovation Discovery}}
\end{center}
\end{frame}

% Slide 8: Week 1 Focus
\begin{frame}
\frametitle{\Large Week 1: Clustering for Innovation}
\framesubtitle{From Scattered Ideas to Innovation Patterns}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{What We'll Learn:}
\normalsize
\begin{itemize}
\item How clustering reveals innovation categories
\item K-means algorithm fundamentals
\item Finding the optimal number of clusters
\item Quality metrics for validation
\item Advanced clustering techniques
\end{itemize}
\end{column}

\begin{column}{0.48\textwidth}
\Large\textbf{Design Applications:}
\normalsize
\begin{itemize}
\item Create innovation archetypes
\item Map innovation evolution paths
\item Identify pain points systematically
\item Prioritize design efforts
\item Scale analysis to thousands of ideas
\end{itemize}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{Goal: Transform scattered ideas into innovation patterns}}
\end{center}
\end{frame}

% The Convergence Flow Visualization
\begin{frame}[plain]
\begin{center}
\includegraphics[width=0.85\textwidth]{charts/convergence_flow.pdf}
\end{center}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{The Convergence Flow: Order from Chaos}}\\
\normalsize\textit{Watch 5000 innovation ideas self-organize into meaningful patterns}
\end{center}
\end{frame}

% TRANSITION TO PART 2
\begin{frame}
\frametitle{\Large Now Let's Get Technical}
\framesubtitle{From Understanding the Problem to Finding Solutions}

\begin{center}
\Large\textbf{We've seen the challenge:}\\
\normalsize
Thousands of innovation ideas with hidden connections\\
\vspace{1em}
\Large\textbf{Traditional approach:}\\
\normalsize
Manual segmentation based on demographics\\
\vspace{1em}
\Large\textcolor{mlgreen}{\textbf{The ML solution:}}\\
\normalsize
Let the data reveal its own natural groups\\
\vspace{2em}
\Large\textcolor{mlpurple}{\textbf{Enter: Clustering Algorithms}}
\end{center}
\end{frame}

% PART 2 SECTION DIVIDER
\begin{frame}[plain]
\begin{center}
\vspace{2em}
\Large\textcolor{mlgreen}{\textbf{PART 2}}\\
\vspace{0.5em}
\Large\textbf{Technical Core}\\
\vspace{2em}
\Large
What we'll master:\\
\vspace{1em}
\normalsize
\begin{itemize}
\item K-means clustering algorithm
\item Finding optimal K with elbow method
\item Distance metrics and quality measures
\item Advanced techniques (DBSCAN, Hierarchical)
\item Feature importance analysis
\end{itemize}
\vspace{2em}
\Large\textcolor{mlpurple}{\textbf{Building your ML toolkit}}
\end{center}
\end{frame}

% PART 2: TECHNICAL CORE (10 slides)

% THE CLUSTERING PROBLEM
\begin{frame}
\frametitle{\Large The Innovation Classification Problem}
\framesubtitle{5000 Ideas - How Do They Connect?}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlred!10, colframe=mlred!50, title=The Pain]
\textbf{Current Reality:}
\begin{itemize}
\item One-size-fits-all solutions
\item Generic innovation categories
\item Missed opportunities
\item Unhappy edge cases
\end{itemize}
\vspace{0.5em}
\textbf{The Cost:}
\begin{itemize}
\item Most innovations get misclassified
\item Features with low adoption rates
\item Inefficient resource allocation
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50, title=The Question]
\Large\textbf{What if we could...}
\normalsize
\begin{itemize}
\item Find natural innovation clusters?
\item Discover innovation patterns?
\item Personalize at scale?
\item Identify opportunity gaps?
\end{itemize}
\vspace{0.5em}
\Large\textcolor{mlpurple}{\textbf{We can!}}\\
\normalsize\textbf{Solution: Clustering}
\end{tcolorbox}
\end{column}
\end{columns}
\end{frame}

% Slide 9: What is Clustering?
\begin{frame}
\frametitle{\Large What is Clustering?}
\framesubtitle{Finding Natural Groups in Innovation Data}

\begin{columns}[T]
\begin{column}{0.43\textwidth}
\Large\textbf{Clustering Finds:}
\normalsize
\begin{itemize}
\item Natural groupings
\item Similar approaches
\item Hidden patterns
\item Innovation relationships
\end{itemize}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50]
\textbf{Key Insight:}\\
Innovations with similar features address similar opportunities
\end{tcolorbox}
\end{column}

\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/chaos_to_clarity.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 10: K-Means Algorithm
\begin{frame}
\frametitle{\Large K-Means: The Workhorse Algorithm}
\framesubtitle{How It Organizes Your Innovations}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{The Process:}
\normalsize
\begin{enumerate}
\item Choose K (number of clusters)
\item Place K random centroids
\item Assign points to nearest centroid
\item Move centroids to cluster mean
\item Repeat until stable
\end{enumerate}

\vspace{0.5em}
\textbf{Strengths:}
\begin{itemize}
\item Fast and scalable
\item Easy to understand
\item Works well for spherical clusters
\end{itemize}
\end{column}

\begin{column}{0.48\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/kmeans_animation.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 11: K-Means Animation
\begin{frame}
\frametitle{\Large K-Means in Action}
\framesubtitle{Step-by-Step Convergence}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/kmeans_animation.pdf}
\end{center}

\begin{center}
\normalsize
Iteration 1 $\rightarrow$ Iteration 3 $\rightarrow$ Iteration 5 $\rightarrow$ \textbf{Converged}
\end{center}
\end{frame}

% PROBLEM: HOW MANY GROUPS?
\begin{frame}
\frametitle{\Large The Goldilocks Problem}
\framesubtitle{Too Few vs. Too Many Groups}

\begin{columns}[T]
\begin{column}{0.32\textwidth}
\begin{tcolorbox}[colback=mlred!10, colframe=mlred!50, title=Too Few (K=2)]
\begin{center}
\textbf{Oversimplification}
\end{center}
\begin{itemize}
\normalsize
\item Mixed segments
\item Lost nuance
\item Generic solutions
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.32\textwidth}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50, title=Just Right (K=5)]
\begin{center}
\textbf{Optimal Balance}
\end{center}
\begin{itemize}
\normalsize
\item Clear segments
\item Actionable insights
\item Manageable complexity
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.32\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Too Many (K=20)]
\begin{center}
\textbf{Analysis Paralysis}
\end{center}
\begin{itemize}
\normalsize
\item Overfitting
\item Tiny segments
\item Impossible to act on
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}

\vspace{1em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{How do we find the sweet spot?}}
\end{center}
\end{frame}

% Slide 12: Choosing K - Elbow Method
\begin{frame}
\frametitle{\Large The Elbow Method}
\framesubtitle{Finding the Optimal Number of Clusters}

\begin{columns}[T]
\begin{column}{0.43\textwidth}
\Large\textbf{Finding the Elbow:}
\normalsize
\begin{itemize}
\item Plot inertia vs K
\item Look for the ``elbow''
\item Balance between:
    \begin{itemize}
    \normalsize
    \item Too few: Mixed groups
    \item Too many: Overfitting
    \end{itemize}
\end{itemize}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50]
\textbf{Optimal K = 5}\\
Best trade-off between simplicity and accuracy
\end{tcolorbox}
\end{column}

\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/elbow_method.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 13: Distance Metrics
\begin{frame}
\frametitle{\Large Distance Metrics}
\framesubtitle{How We Measure Similarity}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/distance_visual.pdf}
\end{center}

\begin{columns}[T]
\begin{column}{0.32\textwidth}
\begin{center}
\textbf{Euclidean}\\
\normalsize Direct distance\\
Best for continuous data
\end{center}
\end{column}

\begin{column}{0.32\textwidth}
\begin{center}
\textbf{Manhattan}\\
\normalsize City-block distance\\
Good for grid-like data
\end{center}
\end{column}

\begin{column}{0.32\textwidth}
\begin{center}
\textbf{Cosine}\\
\normalsize Angle between vectors\\
Ideal for text/preferences
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 14: Cluster Quality
\begin{frame}
\frametitle{\Large Cluster Quality Metrics}
\framesubtitle{How Good Are Your Groups?}

\begin{columns}[T]
\begin{column}{0.43\textwidth}
\Large\textbf{Silhouette Score:}
\normalsize
\begin{itemize}
\item Ranges from -1 to +1
\item Higher = better separation
\item Our score: \textbf{0.73}
\end{itemize}

\vspace{0.5em}
\textbf{What it measures:}
\begin{itemize}
\item Within-cluster cohesion
\item Between-cluster separation
\item Overall cluster validity
\end{itemize}

\vspace{0.5em}
\textcolor{mlgreen}{\textbf{0.73 = Strong clusters!}}
\end{column}

\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/cluster_quality.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% PROBLEM: NON-SPHERICAL GROUPS
\begin{frame}
\frametitle{\Large When Circles Don't Work}
\framesubtitle{Real Innovation Clusters Have Complex Shapes}

\begin{center}
\Large\textbf{K-Means Assumes Spherical Clusters}\\
\vspace{1em}
\normalsize But what about:\\
\vspace{1em}
\begin{itemize}
\item Innovations connected through technology stacks
\item Domain-specific innovation clusters
\item Evolution patterns (incremental, disruptive)
\item Outliers and noise points
\end{itemize}
\vspace{1em}
\Large\textcolor{mlred}{\textbf{K-Means Forces Round Pegs into Round Holes}}\\
\vspace{1em}
\Large\textcolor{mlgreen}{\textbf{Solution: Density-Based Clustering}}
\end{center}
\end{frame}

% Slide 15: Beyond K-Means - DBSCAN
\begin{frame}
\frametitle{\Large DBSCAN: Density-Based Clustering}
\framesubtitle{Finding Natural Boundaries, Not Forcing Shapes}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\Large\textbf{DBSCAN Advantages:}
\normalsize
\begin{itemize}
\item No need to specify K
\item Finds arbitrary shapes
\item Identifies outliers
\item Handles noise well
\end{itemize}

\vspace{0.5em}
\textbf{Perfect for:}
\begin{itemize}
\item Non-spherical patterns
\item Varying densities
\item Outlier detection
\item Exploratory analysis
\end{itemize}
\end{column}

\begin{column}{0.48\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/dbscan_shapes.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 16: DBSCAN Shapes
\begin{frame}
\frametitle{\Large DBSCAN: Complex Patterns}
\framesubtitle{When K-Means Isn't Enough}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/dbscan_shapes.pdf}
\end{center}

\begin{center}
\normalsize
K-Means: Forces spherical shapes | DBSCAN: Finds natural boundaries
\end{center}
\end{frame}

% PROBLEM: MULTIPLE GRANULARITIES
\begin{frame}
\frametitle{\Large The Granularity Challenge}
\framesubtitle{When You Need Multiple Levels of Detail}

\begin{center}
\Large\textbf{Fixed K Gives One View}\\
\vspace{1em}
\normalsize But real relationships are hierarchical:\\
\vspace{1em}
\begin{itemize}
\item Organization: Company → Department → Team → Individual
\item Geography: Country → Region → City → Neighborhood
\item Products: Category → Subcategory → Brand → SKU
\item Innovations: All → Categories → Sub-types → Specific solutions
\end{itemize}
\vspace{1em}
\Large\textcolor{mlred}{\textbf{K-means: Pick 5 groups and that's it}}\\
\vspace{1em}
\Large\textcolor{mlgreen}{\textbf{What if we need flexibility?}}\\
\vspace{0.5em}
\normalsize Solution: See the full hierarchy, cut where needed
\end{center}
\end{frame}

% Slide 17: Hierarchical Clustering
\begin{frame}
\frametitle{\Large Hierarchical Clustering}
\framesubtitle{Building a Tree of Relationships}

\begin{columns}[T]
\begin{column}{0.43\textwidth}
\Large\textbf{Dendrogram Benefits:}
\normalsize
\begin{itemize}
\item Shows cluster hierarchy
\item Multiple granularities
\item Natural relationships
\item No preset K needed
\end{itemize}

\vspace{0.5em}
\textbf{Cut the tree at any level:}
\begin{itemize}
\item High cut = Few clusters
\item Low cut = Many clusters
\item Choose based on needs
\end{itemize}
\end{column}

\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/dendrogram_example.pdf}
\end{center}
\end{column}
\end{columns}
\end{frame}

% Slide 18: Feature Importance
\begin{frame}
\frametitle{\Large What Drives the Clusters?}
\framesubtitle{Feature Importance Analysis}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/feature_importance.pdf}
\end{center}

\begin{center}
\Large\textcolor{mlpurple}{\textbf{Key Insight: Usage frequency matters most!}}
\end{center}
\end{frame}

% TRANSITION TO PART 3
\begin{frame}
\frametitle{\Large From Algorithms to Innovation Insights}
\framesubtitle{What Does This Mean for Innovation Opportunities?}

\begin{center}
\Large\textbf{We've mastered the technical tools:}\\
\normalsize
Clustering, metrics, quality measures\\
\vspace{1em}
\Large\textcolor{mlred}{\textbf{But clusters are just numbers...}}\\
\vspace{1em}
\normalsize
Until we connect them to human needs\\
\vspace{2em}
\Large\textcolor{mlgreen}{\textbf{Let's transform data into empathy}}\\
\vspace{1em}
\normalsize
Each cluster represents innovation opportunities and patterns
\end{center}
\end{frame}

% PART 3 SECTION DIVIDER
\begin{frame}[plain]
\begin{center}
\vspace{2em}
\Large\textcolor{mlorange}{\textbf{PART 3}}\\
\vspace{0.5em}
\Large\textbf{Design Integration}\\
\vspace{2em}
\Large
What we'll create:\\
\vspace{1em}
\normalsize
\begin{itemize}
\item Data-driven personas
\item Empathy maps per segment
\item Cluster-specific journeys
\item Pain point heat maps
\item Design priority matrices
\end{itemize}
\vspace{2em}
\Large\textcolor{mlpurple}{\textbf{Where ML meets human-centered design}}
\end{center}
\end{frame}

% PART 3: DESIGN INTEGRATION (8 slides)

% Slide 19: From Data to Empathy
\begin{frame}
\frametitle{\Large From Data Points to Innovation Insights}
\framesubtitle{Bridging the Technical-Human Gap}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/innovation_patterns_visual.pdf}
\end{center}

\begin{center}
\Large\textcolor{mlpurple}{\textbf{Each cluster represents innovation opportunities}}
\end{center}
\end{frame}

% Slide 20: AI-Generated Personas
\begin{frame}
\frametitle{\Large AI-Generated Innovation Archetypes}
\framesubtitle{Data-Driven Character Development}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/persona_cards.pdf}
\end{center}

\begin{center}
\normalsize
Disruptive | Incremental | Platform-Based | Service-Oriented | Hybrid Models
\end{center}
\end{frame}

% Slide 21: Empathy Maps
\begin{frame}
\frametitle{\Large Cluster-Based Innovation Mapping}
\framesubtitle{Understanding Each Category's Impact}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/empathy_map_clusters.pdf}
\end{center}
\end{frame}

% Slide 22: Journey Mapping
\begin{frame}
\frametitle{\Large Different Evolution Paths for Innovation Types}
\framesubtitle{Innovation Lifecycle Patterns}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/journey_map_clusters.pdf}
\end{center}
\end{frame}

% Slide 23: Pain Points Heatmap
\begin{frame}
\frametitle{\Large Innovation Opportunities by Cluster}
\framesubtitle{Where Each Category Has Potential}

\begin{columns}[T]
\begin{column}{0.65\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/pain_points_heatmap.pdf}
\end{center}
\end{column}

\begin{column}{0.33\textwidth}
\Large\textbf{Key Findings:}
\normalsize
\begin{itemize}
\item Emerging tech: Early stage
\item Disruptive: Scalability
\item Incremental: Integration
\item Platform-based: Network effects
\end{itemize}

\vspace{0.5em}
\textcolor{mlred}{\textbf{Design implication:}}\\
\normalsize One solution won't fit all!
\end{column}
\end{columns}
\end{frame}

% Slide 24: Behavior Patterns
\begin{frame}
\frametitle{\Large Innovation Patterns Revealed}
\framesubtitle{What Clusters Tell Us About Evolution}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/behavior_patterns.pdf}
\end{center}
\end{frame}

% Slide 25: Design Priority Matrix
\begin{frame}
\frametitle{\Large Design Priority Matrix}
\framesubtitle{Where to Focus Your Efforts}

\begin{columns}[T]
\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/design_priority_matrix.pdf}
\end{center}
\end{column}

\begin{column}{0.43\textwidth}
\Large\textbf{Priority Quadrants:}
\normalsize
\begin{itemize}
\item \textcolor{mlred}{\textbf{High Impact + High Effort}}\\
  Strategic initiatives
\item \textcolor{mlgreen}{\textbf{High Impact + Low Effort}}\\
  Quick wins
\item \textcolor{mlorange}{\textbf{Low Impact + Low Effort}}\\
  Fill-ins
\item \textcolor{mlgray}{\textbf{Low Impact + High Effort}}\\
  Avoid
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 26: Stakeholder Network
\begin{frame}
\frametitle{\Large Understanding Innovation Ecosystems}
\framesubtitle{Network Analysis of Innovation Connections}

\begin{center}
\includegraphics[width=0.85\textwidth]{charts/stakeholder_network.pdf}
\end{center}
\end{frame}

% TRANSITION TO PART 4
\begin{frame}
\frametitle{\Large Putting It All Together}
\framesubtitle{From Theory to Practice}

\begin{center}
\Large\textbf{You've learned:}\\
\normalsize
- The clustering algorithms\\
- How to validate quality\\
- Design applications\\
\vspace{1em}
\Large\textcolor{mlpurple}{\textbf{Now let's see it in action}}\\
\vspace{1em}
\normalsize
Real companies using these exact techniques\\
to drive innovation breakthroughs
\end{center}
\end{frame}

% PART 4 SECTION DIVIDER
\begin{frame}[plain]
\begin{center}
\vspace{2em}
\Large\textcolor{mlred}{\textbf{PART 4}}\\
\vspace{0.5em}
\Large\textbf{Summary \& Practice}\\
\vspace{2em}
\Large
What we'll do:\\
\vspace{1em}
\normalsize
\begin{itemize}
\item See real-world success (Spotify)
\item Consolidate key learnings
\item Practice with exercises
\item Preview next week
\item Explore resources
\end{itemize}
\vspace{2em}
\Large\textcolor{mlpurple}{\textbf{From learning to doing}}
\end{center}
\end{frame}

% PART 4: SUMMARY & PRACTICE (5 slides)

% Slide 27: Real-World Clustering Patterns
\begin{frame}
\frametitle{\Large Real-World Clustering Patterns}
\framesubtitle{Common Applications and Success Metrics}

\begin{columns}[T]
\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/clustering_examples.pdf}
\end{center}
\end{column}

\begin{column}{0.43\textwidth}
\Large\textbf{Common Applications:}
\normalsize
\begin{itemize}
\item Innovation portfolio management
\item Technology trend clustering
\item Opportunity space mapping
\item Anomaly detection
\end{itemize}

\vspace{0.5em}
\textbf{Typical Results:}
\begin{itemize}
\item Engagement: +35-45\%
\item Retention: +20-30\%
\item Conversion: +15-25\%
\item Processing time: -60\%
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 28: Key Takeaways
\begin{frame}
\frametitle{\Large Key Takeaways}
\framesubtitle{What We've Learned}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50, title=Technical Skills]
\begin{itemize}
\item K-means clustering algorithm
\item Choosing optimal K with elbow method
\item Silhouette scores for validation
\item DBSCAN for complex shapes
\item Hierarchical clustering
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Design Applications]
\begin{itemize}
\item Data-driven personas
\item Segment-specific journeys
\item Pain point identification
\item Priority matrices
\item Scaled empathy
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{Clustering transforms data into actionable innovation insights}}
\end{center}
\end{frame}

% Slide 29: Implementation Checklist
\begin{frame}
\frametitle{\Large Implementation Checklist}
\framesubtitle{Ensuring Successful Clustering Projects}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50, title=Data Preparation]
\normalsize
\begin{itemize}
\item[$\square$] Collect relevant features
\item[$\square$] Handle missing values
\item[$\square$] Standardize/normalize data
\item[$\square$] Remove outliers if needed
\item[$\square$] Feature engineering complete
\item[$\square$] Data quality verified
\end{itemize}
\end{tcolorbox}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50, title=Algorithm Selection]
\normalsize
\begin{itemize}
\item[$\square$] Choose distance metric
\item[$\square$] Select clustering method
\item[$\square$] Determine optimal K
\item[$\square$] Validate with metrics
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Quality Assurance]
\normalsize
\begin{itemize}
\item[$\square$] Silhouette score > 0.5
\item[$\square$] Cluster sizes balanced
\item[$\square$] Visual inspection done
\item[$\square$] Stability tested
\item[$\square$] Business sense verified
\item[$\square$] Edge cases handled
\end{itemize}
\end{tcolorbox}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlred!10, colframe=mlred!50, title=Common Pitfalls]
\normalsize
\begin{itemize}
\item[$\times$] Forgetting to scale features
\item[$\times$] Wrong distance metric
\item[$\times$] Forcing unnatural K
\item[$\times$] Ignoring outliers
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}
\end{frame}

% Slide 30: Next Week Preview
\begin{frame}
\frametitle{\Large Next Week: Advanced Clustering}
\framesubtitle{Going Deeper into Innovation Patterns}

\begin{columns}[T]
\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/week2_preview.pdf}
\end{center}
\end{column}

\begin{column}{0.43\textwidth}
\Large\textbf{Week 2 Topics:}
\normalsize
\begin{itemize}
\item Density-based clustering
\item Gaussian mixture models
\item Clustering validation
\item Feature engineering
\item Real-time clustering
\end{itemize}

\vspace{0.5em}
\textbf{Design Focus:}
\begin{itemize}
\item Dynamic innovation tracking
\item Evolving innovation landscapes
\item Predictive opportunity analysis
\item Micro-innovation detection
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Slide 31: Resources
\begin{frame}
\frametitle{\Large Resources \& Further Reading}
\framesubtitle{Deepen Your Understanding}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50, title=Technical Resources]
\normalsize
\textbf{Papers:}
\begin{itemize}
\normalsize
\item MacQueen, J. (1967). K-means
\item Ester et al. (1996). DBSCAN
\item Rousseeuw (1987). Silhouettes
\end{itemize}

\textbf{Tools:}
\begin{itemize}
\normalsize
\item scikit-learn clustering
\item Orange data mining
\item KNIME analytics
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Design Resources]
\normalsize
\textbf{Books:}
\begin{itemize}
\normalsize
\item ``Design Thinking'' - Tim Brown
\item ``Sprint'' - Jake Knapp
\item ``Lean UX'' - Jeff Gothelf
\end{itemize}

\textbf{Applications:}
\begin{itemize}
\normalsize
\item Miro (journey mapping)
\item Figma (persona creation)
\item Optimal Workshop
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}

\vspace{0.5em}
\begin{center}
\Large\textcolor{mlpurple}{\textbf{Questions? Let's discuss!}}
\end{center}
\end{frame}

% APPENDIX: TECHNICAL DEEP DIVE
\appendix
\section{Technical Appendix}

% Appendix Slide 1: K-Means Mathematics
\begin{frame}
\frametitle{\Large Appendix: K-Means Mathematics}
\framesubtitle{The Mathematical Foundation}

\Large\textbf{Objective Function (Inertia):}
\normalsize
$$J = \sum_{i=1}^{n} \sum_{j=1}^{k} w_{ij} ||x_i - \mu_j||^2$$

Where:
\begin{itemize}
\item $n$ = number of data points
\item $k$ = number of clusters
\item $w_{ij}$ = 1 if $x_i$ belongs to cluster $j$, 0 otherwise
\item $\mu_j$ = centroid of cluster $j$
\end{itemize}

\vspace{0.5em}
\Large\textbf{Update Rules:}
\normalsize
\begin{enumerate}
\item Assignment: $c^{(i)} = \arg\min_j ||x^{(i)} - \mu_j||^2$
\item Update: $\mu_j = \frac{1}{|S_j|} \sum_{i \in S_j} x^{(i)}$
\end{enumerate}
\end{frame}

% Appendix Slide 2: Distance Metrics Formulas
\begin{frame}
\frametitle{\Large Appendix: Distance Metrics}
\framesubtitle{Mathematical Definitions}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Euclidean Distance:}
$$d(x,y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$$

\vspace{0.5em}
\textbf{Manhattan Distance:}
$$d(x,y) = \sum_{i=1}^{n} |x_i - y_i|$$

\vspace{0.5em}
\textbf{Minkowski Distance:}
$$d(x,y) = \left(\sum_{i=1}^{n} |x_i - y_i|^p\right)^{1/p}$$
\end{column}

\begin{column}{0.48\textwidth}
\textbf{Cosine Similarity:}
$$\cos(\theta) = \frac{x \cdot y}{||x|| \cdot ||y||}$$

\vspace{0.5em}
\textbf{Jaccard Distance:}
$$J(A,B) = 1 - \frac{|A \cap B|}{|A \cup B|}$$

\vspace{0.5em}
\textbf{Mahalanobis Distance:}
$$d(x,y) = \sqrt{(x-y)^T S^{-1} (x-y)}$$
\end{column}
\end{columns}
\end{frame}

% Appendix Slide 3: Silhouette Coefficient
\begin{frame}
\frametitle{\Large Appendix: Silhouette Coefficient}
\framesubtitle{Measuring Cluster Quality}

\Large\textbf{Silhouette Score for point $i$:}
\normalsize
$$s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}$$

Where:
\begin{itemize}
\item $a(i)$ = average distance to points in same cluster
\item $b(i)$ = average distance to points in nearest neighbor cluster
\end{itemize}

\vspace{0.5em}
\Large\textbf{Interpretation:}
\normalsize
\begin{itemize}
\item $s(i) \approx 1$: Well clustered
\item $s(i) \approx 0$: On border between clusters
\item $s(i) \approx -1$: Misclassified
\end{itemize}

\vspace{0.5em}
\Large\textbf{Overall Score:}
\normalsize
$$S = \frac{1}{n} \sum_{i=1}^{n} s(i)$$
\end{frame}

% Appendix Slide 4: PCA for Visualization
\begin{frame}
\frametitle{\Large Appendix: PCA for Cluster Visualization}
\framesubtitle{Dimensionality Reduction}

\begin{columns}[T]
\begin{column}{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{charts/pca_clusters.pdf}
\end{center}
\end{column}

\begin{column}{0.43\textwidth}
\Large\textbf{PCA Process:}
\normalsize
\begin{enumerate}
\item Standardize data
\item Compute covariance matrix
\item Find eigenvectors/values
\item Select top 2 components
\item Transform data
\end{enumerate}

\vspace{0.5em}
\textbf{Variance Explained:}
\begin{itemize}
\item PC1: 45.2\%
\item PC2: 28.7\%
\item Total: 73.9\%
\end{itemize}
\end{column}
\end{columns}
\end{frame}

% Appendix Slide 5: DBSCAN Algorithm
\begin{frame}
\frametitle{\Large Appendix: DBSCAN Algorithm}
\framesubtitle{Density-Based Clustering Details}

\Large\textbf{Key Parameters:}
\normalsize
\begin{itemize}
\item $\epsilon$ (eps): Maximum distance between points
\item MinPts: Minimum points to form dense region
\end{itemize}

\vspace{0.5em}
\Large\textbf{Point Classification:}
\normalsize
\begin{itemize}
\item \textbf{Core point}: Has $\geq$ MinPts within $\epsilon$
\item \textbf{Border point}: Within $\epsilon$ of core point
\item \textbf{Noise point}: Neither core nor border
\end{itemize}

\vspace{0.5em}
\Large\textbf{Algorithm Steps:}
\normalsize
\begin{enumerate}
\item Find all core points
\item Form clusters from core points within $\epsilon$
\item Assign border points to clusters
\item Mark remaining as noise
\end{enumerate}
\end{frame}

% Appendix Slide 6: Implementation Hints
\begin{frame}
\frametitle{\Large Appendix: Implementation Guidelines}
\framesubtitle{Practical Considerations}

\begin{columns}[T]
\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlblue!10, colframe=mlblue!50, title=Data Preparation]
\normalsize
\begin{itemize}
\item Standardize features
\item Handle missing values
\item Remove outliers (if needed)
\item Feature selection/engineering
\item Consider scaling methods
\end{itemize}
\end{tcolorbox}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlgreen!10, colframe=mlgreen!50, title=Algorithm Selection]
\normalsize
\begin{itemize}
\item K-means: Spherical, similar size
\item DBSCAN: Arbitrary shapes
\item Hierarchical: Nested structure
\item GMM: Overlapping clusters
\end{itemize}
\end{tcolorbox}
\end{column}

\begin{column}{0.48\textwidth}
\begin{tcolorbox}[colback=mlorange!10, colframe=mlorange!50, title=Validation Methods]
\normalsize
\begin{itemize}
\item Silhouette score
\item Davies-Bouldin index
\item Calinski-Harabasz score
\item Visual inspection
\item Domain expert review
\end{itemize}
\end{tcolorbox}

\vspace{0.5em}
\begin{tcolorbox}[colback=mlred!10, colframe=mlred!50, title=Common Pitfalls]
\normalsize
\begin{itemize}
\item Not scaling features
\item Wrong distance metric
\item Ignoring outliers
\item Over-clustering
\item Forcing clusters
\end{itemize}
\end{tcolorbox}
\end{column}
\end{columns}
\end{frame}

\end{document}